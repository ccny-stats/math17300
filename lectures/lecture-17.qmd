---
title: Lecture 17
subtitle: The Central Limit Theorem and the Sample Mean
format: html
date: 2023-11-07
---

```{r}
#| include: false
g <- glue::glue
library(ggplot2)
sapply(list.files(here::here('R'), full.names = T), source)
```

## Section 7.2 Statistics and Sampling Distributions (Abridged)

- The sampling distribution of a statisstic is the probability distribution for the possible values of the statistic that result when random samples of size *n* are repeatedly drawn from the population.

- Example:

Let's say each one of you goes out and finds 25 people and find their average height. That would give us 30 estimates the average height of 25 people. We can then create a histogram of those 30 estimates and describe that probability distribution.

For example, let say the heights of students are normally distributed with $\mu = 5$ and $\sigma = 1$. Can you make any guesses about what the distribution of the *averages* of 25 students would look like? What about the maximum of each group of 25 students?
\
\
\
\
\
\
\
\
\
\





## Section 7.3 The Central Limit Theorem and the Sample Mean


### The Central Limit Theorem

- The sums and means of a random samples of measurements drawn from a population tend to have an approximately normal distribution. 


- Let's roll one die  and take the average of the sum of dots on the face (very simple for one die)


```{r}
vals <- tibble::tibble(
    x = 1:6,
    y = 1/6
)

vals |> 
ggplot(aes(x = x, y = y)) +
geom_bar(stat = "identity") + 
scale_x_continuous(breaks = 1:6, name = "x_bar") +
scale_y_continuous(limits = c(0, .3), name = "p(x_bar)")



```


Now let's now roll two dice and average the two values we see:

```{r}
#| tbl-cap: Sums of the upper faces of two dice


expand.grid(
    die_1 = 1:6,
    die_2 = 1:6
) |> 
transform(die_sum = die_1 + die_2) |> 
tidyr::pivot_wider(names_from = die_1, values_from = die_sum) |> 
flextable::flextable() |> 
flextable::set_header_labels(die_2 = 'Second Die')  |> 
flextable::bold(j = 1)  |> 
flextable::bold(i = 1, part = "header") |> 
flextable::add_header_lines("First Die")

```

- We can use this to come up with the averages - divide each number in the above table by 2.

```{r}
#| tbl-cap: Sampling Distribution of $\bar x$
expand.grid(
    die_1 = 1:6,
    die_2 = 1:6
) |> 
transform(die_avg = (die_1 + die_2)/2)  |> 
dplyr::count(die_avg)  |> 
transform(p = round(n /36, 3)) |> 
flextable::flextable() |> 
flextable::set_header_labels(die_avg = "xbar", n = "N", p = "Freq")
```

```{r}
#| fig-cap: Sampling Distribution of $\bar x$
expand.grid(
    die_1 = 1:6,
    die_2 = 1:6
) |> 
transform(die_avg = (die_1 + die_2)/2)  |> 
dplyr::count(die_avg)  |> 
transform(p = round(n /36, 10)) |> 
ggplot(aes(x = die_avg, y = p)) + 
geom_bar(stat = "identity") + 
scale_x_continuous(breaks = 1:6, name = "x_bar") +
scale_y_continuous(limits = c(0, .3), name = "p(x_bar)")


```


- The above is looking mound shaped - even though we started with a uniform distribution.


- Lets run this for 3 and 4 dice as well and compare all four graphs. What can we say about the $\mu$ and $\sigma$


```{r}
#| label: fig-charts
#| fig-subcap: 
#|   - "Average of 1 Die"
#|   - "Average of 2 Dice"
#|   - "Average of 3 Dice"
#|   - "Average pf 4 Dice" 
#| layout-ncol: 2
#| fig-cap: Sampling Distribution of $\bar x$

vals <- tibble::tibble(
    x = 1:6,
    y = 1/6
)

vals |> 
ggplot(aes(x = x, y = y)) +
geom_bar(stat = "identity") + 
scale_x_continuous(breaks = 1:6, name = "x_bar") +
scale_y_continuous(limits = c(0, .2), name = "p(x_bar)")



 
expand.grid(
    die_1 = 1:6,
    die_2 = 1:6
) |> 
transform(die_avg = (die_1 + die_2)/2)  |> 
dplyr::count(die_avg)  |> 
transform(p = round(n /36, 10)) |> 
ggplot(aes(x = die_avg, y = p)) + 
geom_bar(stat = "identity") + 
scale_x_continuous(breaks = 1:6, name = "x_bar") +
scale_y_continuous(limits = c(0, .2), name = "p(x_bar)")


 
expand.grid(
    die_1 = 1:6,
    die_2 = 1:6,
    die_3 = 1:6
) |> 
transform(die_avg = (die_1 + die_2 + die_3)/3)  |> 
dplyr::count(die_avg)  |> 
transform(p = round(n /6^3, 10)) |> 
ggplot(aes(x = die_avg, y = p)) + 
geom_bar(stat = "identity") + 
scale_x_continuous(breaks = 1:6, name = "x_bar") +
scale_y_continuous(limits = c(0, .2), name = "p(x_bar)")


expand.grid(
    die_1 = 1:6,
    die_2 = 1:6,
    die_3 = 1:6,
    die_4 = 1:6
) |> 
transform(die_avg = (die_1 + die_2 + die_3 + die_4)/4)  |> 
dplyr::count(die_avg)  |> 
transform(p = round(n /6^4, 10)) |> 
ggplot(aes(x = die_avg, y = p)) + 
geom_bar(stat = "identity") + 
scale_x_continuous(breaks = 1:6, name = "x_bar") +
scale_y_continuous(limits = c(0, .2), name = "p(x_bar)")


```



#### CLT Definition

If random samples of *n* observations are drawn from a nonnormal popuilation with finite mean $\mu$ and standard deviation $\sigma$, then, when $n$ is large, the sampling distribution of the sample mean $\bar x$ is approximately normally distributed with mean = $\mu$ and standard deviation = $\frac{\sigma}{\sqrt{n}}$

The approximation becomes more accurate *n* becomes large.

The Central Limit Theorem can be restated to the sum of the sample measurements, which, as *n* becomes large, also has an approximately normal distribution with mean $n \mu$ and standard deviation $\sigma \sqrt{n}$


### Homework

```{r}
get_lecture_homework(20)
```

Answers: [Section 7.3](/homework/chapter-07.qmd#section-3)