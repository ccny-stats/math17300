---
title: Lecture 17/18
subtitle: The Central Limit Theorem and the Sample Mean
format: html
date: 2023-11-07
---

```{r}
#| include: false
g <- glue::glue
library(ggplot2)
sapply(list.files(here::here('R'), full.names = T), source)
```

## Section 7.2 Statistics and Sampling Distributions (Abridged)

-   The sampling distribution of a statistic is the probability distribution for the possible values of the statistic that result when random samples of size *n* are repeatedly drawn from the population.

-   Example:

Let's say each one of you goes out and finds 25 people and find their average height. That would give us 30 estimates the average height of 25 people. We can then create a histogram of those 30 estimates and describe that probability distribution.

For example, let say the heights of students are normally distributed with $\mu = 5$ and $\sigma = 1$. Can you make any guesses about what the distribution of the *averages* of 25 students would look like?\
\
\
\
\
\
\
\
\
\

## Section 7.3 The Central Limit Theorem and the Sample Mean

### The Central Limit Theorem

-   The sums and means of a random samples of measurements drawn from a population tend to have an approximately normal distribution.

-   Let's roll one die and take the average of the sum of dots on the face (very simple for one die)

```{r}
vals <- tibble::tibble(
    x = 1:6,
    y = 1/6
)

vals |> 
ggplot(aes(x = x, y = y)) +
geom_bar(stat = "identity") + 
scale_x_continuous(breaks = 1:6, name = "x_bar") +
scale_y_continuous(limits = c(0, .3), name = "p(x_bar)")



```

Now let's now roll two dice and average the two values we see:

```{r}
#| tbl-cap: Sums of the upper faces of two dice


expand.grid(
    die_1 = 1:6,
    die_2 = 1:6
) |> 
transform(die_sum = die_1 + die_2) |> 
tidyr::pivot_wider(names_from = die_1, values_from = die_sum) |> 
flextable::flextable() |> 
flextable::set_header_labels(die_2 = 'Second Die')  |> 
flextable::bold(j = 1)  |> 
flextable::bold(i = 1, part = "header") |> 
flextable::add_header_lines("First Die")

```

-   We can use this to come up with the averages - divide each number in the above table by 2.

```{r}
#| tbl-cap: Sampling Distribution of $\bar x$
expand.grid(
    die_1 = 1:6,
    die_2 = 1:6
) |> 
transform(die_avg = (die_1 + die_2)/2)  |> 
dplyr::count(die_avg)  |> 
transform(p = round(n /36, 3)) |> 
flextable::flextable() |> 
flextable::set_header_labels(die_avg = "xbar", n = "N", p = "Freq")
```

```{r}
#| fig-cap: Sampling Distribution of $\bar x$
expand.grid(
    die_1 = 1:6,
    die_2 = 1:6
) |> 
transform(die_avg = (die_1 + die_2)/2)  |> 
dplyr::count(die_avg)  |> 
transform(p = round(n /36, 10)) |> 
ggplot(aes(x = die_avg, y = p)) + 
geom_bar(stat = "identity") + 
scale_x_continuous(breaks = 1:6, name = "x_bar") +
scale_y_continuous(limits = c(0, .3), name = "p(x_bar)")


```

-   The above is looking mound shaped - even though we started with a uniform distribution.

-   Lets run this for 3 and 4 dice as well and compare all four graphs. What can we say about the $\mu$ and $\sigma$

```{r}
#| label: fig-charts
#| fig-subcap: 
#|   - "Average of 1 Die"
#|   - "Average of 2 Dice"
#|   - "Average of 3 Dice"
#|   - "Average pf 4 Dice" 
#| layout-ncol: 2
#| fig-cap: Sampling Distribution of $\bar x$

vals <- tibble::tibble(
    x = 1:6,
    y = 1/6
)

vals |> 
ggplot(aes(x = x, y = y)) +
geom_bar(stat = "identity") + 
scale_x_continuous(breaks = 1:6, name = "x_bar") +
scale_y_continuous(limits = c(0, .2), name = "p(x_bar)")



 
expand.grid(
    die_1 = 1:6,
    die_2 = 1:6
) |> 
transform(die_avg = (die_1 + die_2)/2)  |> 
dplyr::count(die_avg)  |> 
transform(p = round(n /36, 10)) |> 
ggplot(aes(x = die_avg, y = p)) + 
geom_bar(stat = "identity") + 
scale_x_continuous(breaks = 1:6, name = "x_bar") +
scale_y_continuous(limits = c(0, .2), name = "p(x_bar)")


 
expand.grid(
    die_1 = 1:6,
    die_2 = 1:6,
    die_3 = 1:6
) |> 
transform(die_avg = (die_1 + die_2 + die_3)/3)  |> 
dplyr::count(die_avg)  |> 
transform(p = round(n /6^3, 10)) |> 
ggplot(aes(x = die_avg, y = p)) + 
geom_bar(stat = "identity") + 
scale_x_continuous(breaks = 1:6, name = "x_bar") +
scale_y_continuous(limits = c(0, .2), name = "p(x_bar)")


expand.grid(
    die_1 = 1:6,
    die_2 = 1:6,
    die_3 = 1:6,
    die_4 = 1:6
) |> 
transform(die_avg = (die_1 + die_2 + die_3 + die_4)/4)  |> 
dplyr::count(die_avg)  |> 
transform(p = round(n /6^4, 10)) |> 
ggplot(aes(x = die_avg, y = p)) + 
geom_bar(stat = "identity") + 
scale_x_continuous(breaks = 1:6, name = "x_bar") +
scale_y_continuous(limits = c(0, .2), name = "p(x_bar)")


```

#### CLT Definition

If random samples of *n* observations are drawn from a nonnormal population with finite mean $\mu$ and standard deviation $\sigma$, then, when $n$ is large, the sampling distribution of the sample mean $\bar x$ is approximately normally distributed with mean = $\mu$ and standard deviation = $\frac{\sigma}{\sqrt{n}}$

The approximation becomes more accurate *n* becomes large.

The Central Limit Theorem can be restated to the sum of the sample measurements, which, as *n* becomes large, also has an approximately normal distribution with mean $n \mu$ and standard deviation $\sigma \sqrt{n}$

#### How large does *n* need to be?

-   If the sampled population is normal, then the sampling distribution of $\bar x$ will also be normal.
-   If the sampled population is approximately symmetric, then $n \ge 3$
-   If the sampled population is skewed then $n \ge 30$

### Sampling Distribution of the Sample Mean

-   The goal is to estimate the population mean $\mu$

-   How do we do that using our sample? Should we estimate it with the sample mean ($\bar x$), maybe the median?

-   Three main idea about choosing an estimator:

1.  Is it hard to calculate?
2.  Does it produce estimates that are generally too high or too low?
3.  Is it more or less variable than other possible estimators?

The sample mean is best in this case. It's easy to that of course it should be sample mean - however, think about our estimate of the population variance from the sample variance - the sample variance has a different formula.

#### The Sampling Distributino of the Sample Mean, $\bar x$

If a random sample of *n* measurements is selected from a population with mean $\mu$ and standard deviation $\sigma$, the sampling distribution of the sample mean $\bar x$ will have mean $\mu$ and standard deviation $\frac{\sigma}{\sqrt{n}}$.

-   If the population is normal, then the sampling distribution of $\bar x$ is normal no matter the size of $n$.
-   If the population is nonnormal, then this works for $n \ge 30$

### Standard Error of the Sample Mean

The standard deviation of a statistic used to estimate a population parameter is also called the standard error of the estimator. The standard error of $\bar x$ is $\frac{\sigma}{\sqrt{n}}$

In order to calculate probabilities for the Sample Mean - we can convert to a z-score like we have done before - using the standard error for the denominator:

$$
z = \frac{\bar x - \mu}{\sigma/\sqrt{n}}
$$

Note that in this case we are given the population standard deviation. If we weren't, we could calculate it from the sample and plug in $s$ of $\sigma$ above.

### Example 7.4

The duration of Alzheimer's disease from the time symptoms first appear until death ranges from 3 to 20 years; the average is 8 years with a standard deviation of 4 years. The administrator selects the medical records of 30 deceased Alzheimer's patients from the medical center's database and records the average duration. Find the approximate probabilities for these events:

1.  The average duration is less than 7 years.
2.  The average duration exceeds 7 years.
3.  The average duration lies within 1 year of the population mean ($\mu = 8$)

Quick aside - what's happening?

Here is a probability distribution that has a mean of 8 and standard deviation of 4 - and it runs from 3 to 20.

```{r}
rbeta_mean_sd <- function(n, v_min, v_max, v_mean, v_sd) {
    width <- v_max - v_min
    checkmate::assert_number(width, lower = 0, finite = TRUE)
    checkmate::assert_true(width > 0)

    mu <- (v_mean - v_min) / width
    var <- (v_sd / width)^2
    checkmate::assert_number(var, lower = 0, upper = mu * (1 - mu))

    shape1 <- ((1 - mu) / var - 1 / mu) * mu^2
    shape2 <- shape1 * (1 / mu - 1)


    beta_draws <- rbeta(n, shape1, shape2)
    beta_draws <- beta_draws * width + v_min
    attr(beta_draws, "shape1") <- shape1
    attr(beta_draws, "shape2") <- shape2
    attr(beta_draws, "definition") <- c(
        min = v_min,
        max = v_max,
        mean = v_mean,
        sd = v_sd
    )
    beta_draws
}

beta_params <- rbeta_mean_sd(1, 3, 20, 8, 4)
beta_def <- attr(beta_params, "definition")
width <- beta_def["max"] - beta_def["min"]
population_plot_data <- tibble::tibble(
    x = seq(beta_def["min"], beta_def["max"], length.out = 200),
    p_x = dbeta((x - beta_def["min"]) / width, shape1 = attr(beta_params, "shape1"), shape2 = attr(beta_params, "shape2"))
)

ggplot(population_plot_data, aes(x = x, y = p_x)) +
    geom_line() +
    theme_minimal() +
    scale_x_continuous(breaks = 3:20)



```

I can then pick 30 people - this is what the researcher does.

```{r}
set.seed(20231105)
first_sample <- rbeta_mean_sd(30, 3, 20, 8, 4)
hist(first_sample)
round(first_sample, 1) |> as.numeric() |> sort()
```

Mean:

```{r}
mean(first_sample)
```

The questions are asking about that first sample - we chose one group of 30 - but a different group of 30 may have a different mean.

Here is another group:

```{r}
set.seed(20231106)
second_sample <- rbeta_mean_sd(30, 3, 20, 8, 4)
hist(second_sample)
round(second_sample, 1) |> as.numeric() |> sort()
```

Mean:

```{r}
mean(second_sample)
```

Now let's take 1000 samples of 30 and plot the histogram of the *means*.

```{r}
set.seed(20231105)
all_means <- lapply(1:1000, function(.i) {
   rbeta_mean_sd(30, 3, 20, 8, 4) 
}) |> sapply(mean)
data.frame(x = all_means) |> 
ggplot(aes(x = x)) +
geom_histogram()
```

This is the curve we are interested in using to answer the questions below. It has approximately $\mu = 8$ and $SE = \sigma/\sqrt{n} = 4/\sqrt{30} = .73$

1.  The average duration is less than 7 years.\
    \
    \
    \
    \
    \
    \
    \

.0853

2.  The average duration exceeds 7 years.\
    \
    \
    \
    \
    \
    \
    \
    $1 - .0853 = .9147$

3.  The average duration lies within 1 year of the population mean ($\mu = 8$)\
    \
    \
    \
    \
    \
    \

.8294

### Example 7.5

To determine whether a bottling machine is working satisfactorily, a production line manager randomly samples ten 12-ounce bottles every hour and measures the amount of beverage in each bottle.

If records show that the amount of fill per bottle is normally distributed, with a standard deviation of .2 ounce, and if the bottling machine is set to produce a mean fill per bottle of 12.1 ounces, what is the probability that the sample mean $\bar x$ of the 10 test bottles is less than 12 ounces?\
\
\
\
\
\
\
\
\
\
\
\

$P( \bar x \lt 12) = P(z \lt -1.58) = .0571$

What's a possible issue with this strategy? What happens if we run this test 100 times - is it possible we get a false positive?

One way to deal with this is to take a second larger sample if

### Homework

```{r}
get_lecture_homework(21)
```

Answers: [Section 7.3](/homework/chapter-07.qmd#section-3)