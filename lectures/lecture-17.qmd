---
title: Lecture 17
subtitle: The Central Limit Theorem and the Sample Mean
format: html
date: 2023-11-07
---

```{r}
#| include: false
g <- glue::glue
library(ggplot2)
sapply(list.files(here::here('R'), full.names = T), source)
```

## Section 7.2 Statistics and Sampling Distributions (Abridged)

- The sampling distribution of a statisstic is the probability distribution for the possible values of the statistic that result when random samples of size *n* are repeatedly drawn from the population.

- Example:

Let's say each one of you goes out and finds 25 people and find their average height. That would give us 30 estimates the average height of 25 people. We can then create a histogram of those 30 estimates and describe that probability distribution.

For example, let say the heights of students are normally distributed with $\mu = 5$ and $\sigma = 1$. Can you make any guesses about what the distribution of the *averages* of 25 students would look like? What about the maximum of each group of 25 students?
\
\
\
\
\
\
\
\
\
\





## Section 7.3 The Central Limit Theorem and the Sample Mean


### The Central Limit Theorem

- The sums and means of a random samples of measurements drawn from a population tend to have an approximately normal distribution. 


- Let's roll one die  and take the average of the sum of dots on the face (very simple for one die)


```{r}
vals <- tibble::tibble(
    x = 1:6,
    y = 1/6
)

vals |> 
ggplot(aes(x = x, y = y)) +
geom_bar(stat = "identity") + 
scale_x_continuous(breaks = 1:6, name = "x_bar") +
scale_y_continuous(limits = c(0, .3), name = "p(x_bar)")



```


Now let's now roll two dice and average the two values we see:

```{r}
#| tbl-cap: Sums of the upper faces of two dice


expand.grid(
    die_1 = 1:6,
    die_2 = 1:6
) |> 
transform(die_sum = die_1 + die_2) |> 
tidyr::pivot_wider(names_from = die_1, values_from = die_sum) |> 
flextable::flextable() |> 
flextable::set_header_labels(die_2 = 'Second Die')  |> 
flextable::bold(j = 1)  |> 
flextable::bold(i = 1, part = "header") |> 
flextable::add_header_lines("First Die")

```

- We can use this to come up with the averages - divide each number in the above table by 2.

```{r}
#| tbl-cap: Sampling Distribution of $\bar x$
expand.grid(
    die_1 = 1:6,
    die_2 = 1:6
) |> 
transform(die_avg = (die_1 + die_2)/2)  |> 
dplyr::count(die_avg)  |> 
transform(p = round(n /36, 3)) |> 
flextable::flextable() |> 
flextable::set_header_labels(die_avg = "xbar", n = "N", p = "Freq")
```

```{r}
#| fig-cap: Sampling Distribution of $\bar x$
expand.grid(
    die_1 = 1:6,
    die_2 = 1:6
) |> 
transform(die_avg = (die_1 + die_2)/2)  |> 
dplyr::count(die_avg)  |> 
transform(p = round(n /36, 10)) |> 
ggplot(aes(x = die_avg, y = p)) + 
geom_bar(stat = "identity") + 
scale_x_continuous(breaks = 1:6, name = "x_bar") +
scale_y_continuous(limits = c(0, .3), name = "p(x_bar)")


```


- The above is looking mound shaped - even though we started with a uniform distribution.


- Lets run this for 3 and 4 dice as well and compare all four graphs. What can we say about the $\mu$ and $\sigma$


```{r}
#| label: fig-charts
#| fig-subcap: 
#|   - "Average of 1 Die"
#|   - "Average of 2 Dice"
#|   - "Average of 3 Dice"
#|   - "Average pf 4 Dice" 
#| layout-ncol: 2
#| fig-cap: Sampling Distribution of $\bar x$

vals <- tibble::tibble(
    x = 1:6,
    y = 1/6
)

vals |> 
ggplot(aes(x = x, y = y)) +
geom_bar(stat = "identity") + 
scale_x_continuous(breaks = 1:6, name = "x_bar") +
scale_y_continuous(limits = c(0, .2), name = "p(x_bar)")



 
expand.grid(
    die_1 = 1:6,
    die_2 = 1:6
) |> 
transform(die_avg = (die_1 + die_2)/2)  |> 
dplyr::count(die_avg)  |> 
transform(p = round(n /36, 10)) |> 
ggplot(aes(x = die_avg, y = p)) + 
geom_bar(stat = "identity") + 
scale_x_continuous(breaks = 1:6, name = "x_bar") +
scale_y_continuous(limits = c(0, .2), name = "p(x_bar)")


 
expand.grid(
    die_1 = 1:6,
    die_2 = 1:6,
    die_3 = 1:6
) |> 
transform(die_avg = (die_1 + die_2 + die_3)/3)  |> 
dplyr::count(die_avg)  |> 
transform(p = round(n /6^3, 10)) |> 
ggplot(aes(x = die_avg, y = p)) + 
geom_bar(stat = "identity") + 
scale_x_continuous(breaks = 1:6, name = "x_bar") +
scale_y_continuous(limits = c(0, .2), name = "p(x_bar)")


expand.grid(
    die_1 = 1:6,
    die_2 = 1:6,
    die_3 = 1:6,
    die_4 = 1:6
) |> 
transform(die_avg = (die_1 + die_2 + die_3 + die_4)/4)  |> 
dplyr::count(die_avg)  |> 
transform(p = round(n /6^4, 10)) |> 
ggplot(aes(x = die_avg, y = p)) + 
geom_bar(stat = "identity") + 
scale_x_continuous(breaks = 1:6, name = "x_bar") +
scale_y_continuous(limits = c(0, .2), name = "p(x_bar)")


```



#### CLT Definition

If random samples of *n* observations are drawn from a nonnormal popuilation with finite mean $\mu$ and standard deviation $\sigma$, then, when $n$ is large, the sampling distribution of the sample mean $\bar x$ is approximately normally distributed with mean = $\mu$ and standard deviation = $\frac{\sigma}{\sqrt{n}}$

The approximation becomes more accurate *n* becomes large.

The Central Limit Theorem can be restated to the sum of the sample measurements, which, as *n* becomes large, also has an approximately normal distribution with mean $n \mu$ and standard deviation $\sigma \sqrt{n}$

#### How large does *n* need to be?

- If the sampled population is normal, then the sampling distribution of $\bar x$ will also be normal.
- If the sampled population is approximately symmetric, then $n \ge 3$
- If the sampled population is skewed then $n \ge 30$

### Sampling Distribution of the Sample Mean

- The goal is to estimate the population mean $\mu$
- How do we do that using our sample? Should we estimate it with the sample mean ($\bar x$), maybe the median?

- Three main idea about choosing an estimator:

1. Is it hard to calculate?
2. Does it produce estimates that are generally too high or too low?
3. Is it more or less variable than other psosible estimators?

The sample mean is best in this case. It's easy to that of course it should be sample mean - however, think about our estimate of the population variance from the sample variance - the sample variance has a different formula.

#### The Sampling Distributino of the Sample Mean, $\bar x$

If a random sample of *n$ measuremetns is selected from a population with mean $\mu$ and standard deviation $\sigma$, the sampling distribution of the sample mean $\bar x$ will have mean $\mu$ and standard deviation $\frac{\sigma}{\sqrt{n}}$.

- If the population is normal, then the sampling distribution fo $\bar x$ is normal no matter the size of $n$.
- If the population is nonnormal, then this works for $n \ge 30$

### Standard Error of the Sample Mean

The standard deviation of a statistic used to estimate a population paramaeter is also called the standard error of the estimator. The standard error of $\bar x$ is $\frac{\sigma}{sqrt{n}}$

In order to calculate probabilities for the Sample Mean - we can convert to a z-score like we have done before - useing the standard error for the denominator:

$$
z = \frac{\bar x - \mu}{\sigma/\sqrt{n}}
$$


Note that in this case we are given the population standard deviation. If we weren't, we could calculate it from the sample and plug in $s$ of $\sigma$ above. 

### Homework

```{r}
get_lecture_homework(20)
```

Answers: [Section 7.3](/homework/chapter-07.qmd#section-3)